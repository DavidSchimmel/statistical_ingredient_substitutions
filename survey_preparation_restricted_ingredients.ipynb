{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the survey with the more restricted ingredient set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from generic_preprocessing import (make_recipes_extended_dict)\n",
    "\n",
    "from calc_recipe_ingredient_info_distances import collectSomeRecipeRecommendations, get_all_comments, get_all_mutual_info, evalRecommendations, getRecommendationsBasedOnMutualInformationRole, get_graph_nodes, get_all_gt_recipes, get_recipes_per_ingredient, get_recipes_per_ingredient_pairs, get_all_frequencies,getNaiveBayesRecommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERED_RECIPE_IDS_PATH = os.path.abspath(\"./outputs/sorted_recipe_ids_list.pkl\")\n",
    "TRAIN_COMMENTS_PATH = os.path.abspath(\"./inputs/train_comments_subs.pkl\") # train recipes with substitutions\n",
    "TEST_COMMENTS_PATH = os.path.abspath(\"./inputs/test_comments_subs.pkl\") # test recipes with substitutions\n",
    "VAL_COMMENTS_PATH = os.path.abspath(\"./inputs/val_comments_subs.pkl\") # validation recipes with substitutions\n",
    "GRAPH_NODES_PATH = os.path.abspath(\"./inputs/graph/nodes_191120.csv\")\n",
    "\n",
    "MUTUAL_INFO_DICT_PATH = os.path.abspath(\"./outputs/mutual_info_dict_with_self_info.pkl\")\n",
    "RECIPES_PER_INGREDIENT_SMALL_PATH = os.path.abspath(\n",
    "    \"./outputs/recipes_per_ingredient_small.pkl\"\n",
    ")\n",
    "RECIPES_PER_INGREDIENT_PAIRS_SMALL_PATH = os.path.abspath(\n",
    "    \"./outputs/recipes_per_ingredient_pairs_small.pkl\"\n",
    ")\n",
    "PROCESSED_RECIPES_PATH = os.path.abspath(\"./outputs/processed_recipes.pkl\")\n",
    "PATH_ONE_HOT_RECIPE_INGREDIENTS = os.path.abspath(\"./outputs/one_hot_recipe_ingredients.pkl\")\n",
    "\n",
    "EXTENDED_RECIPES_PATH_OLD = os.path.abspath(\"./inputs/extended_recipes_with_instructions_and_titles.json\")\n",
    "\n",
    "EXTENDED_RECIPES_PATH = os.path.abspath(\"./inputs/extended_recipes_with_quantities.json\")\n",
    "\n",
    "\n",
    "SURVEY_COMPLETE_SUB_TUPLE_AND_RECIPE_SET_PATH = os.path.abspath(\"./outputs/suvey_all_subs_and_recipes.json\")\n",
    "\n",
    "SURVEY_QUESTION_SET_A_PATH = os.path.abspath(\"./outputs/suvey_question_set_restrained_a.json\")\n",
    "SURVEY_QUESTION_SET_B_PATH = os.path.abspath(\"./outputs/suvey_question_set_restrained_b.json\")\n",
    "SURVEY_QUESTION_500_SET_PATH = os.path.abspath(\"./outputs/suvey_question_set_restrained_500.json\")\n",
    "SURVEY_QUESTION_500_UPDATED_SET_PATH = os.path.abspath(\"./outputs/suvey_question_set_enriched_500.json\")\n",
    "\n",
    "ARCELIC_TO_R1M_RAW_PATH = os.path.abspath(\"./outputs/arcelic_raw_to_r1m.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260\n"
     ]
    }
   ],
   "source": [
    "ingredients = get_graph_nodes(GRAPH_NODES_PATH)\n",
    "\n",
    "with open(SURVEY_COMPLETE_SUB_TUPLE_AND_RECIPE_SET_PATH, \"r\") as survey_data_path:\n",
    "    survey_data = json.load(survey_data_path)\n",
    "\n",
    "print(len(survey_data))\n",
    "\n",
    "with open(ARCELIC_TO_R1M_RAW_PATH, \"r\") as arcelic_to_r1m_file:\n",
    "    arcelic_to_r1m_raw = json.load(arcelic_to_r1m_file)\n",
    "\n",
    "QUALTRICS_SURVEY_DATA_FILE_PATH = os.path.abspath(\"./inputs/survey_recipes_cgpt_suggestions.json\")\n",
    "with open(QUALTRICS_SURVEY_DATA_FILE_PATH, \"r\") as qualstrics_data_file:\n",
    "    qualtrics_data = json.load(qualstrics_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipes with comments, lists, names, and gt_truths\n",
    "with open(EXTENDED_RECIPES_PATH, 'r') as recipe_extended_with_original_info:\n",
    "    extended_recipes = json.load(recipe_extended_with_original_info)\n",
    "\n",
    "recipes_extended_dict = make_recipes_extended_dict(extended_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all the parsed labels are present in FlavorGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10%_cream', '18%_table_cream', '2%_cheddar_cheese', '2%_evaporated_milk', '2%_milk', '2%_mozzarella_cheese', '35%_cream', '80%_lean_ground_beef', '85%_lean_ground_beef', '90%_lean_ground_beef']\n"
     ]
    }
   ],
   "source": [
    "# get set of distinct r1m ingredients from the mapping:\n",
    "distinct_mapping_targets = sorted({x for v in arcelic_to_r1m_raw.values() for x in v})\n",
    "print(distinct_mapping_targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "found_labels = []\n",
    "not_found_labels = []\n",
    "\n",
    "for mapped_target in distinct_mapping_targets:\n",
    "    if mapped_target in ingredients:\n",
    "        found_labels.append(mapped_target)\n",
    "    else:\n",
    "        not_found_labels.append(mapped_target)\n",
    "\n",
    "print(len(found_labels))\n",
    "print(len(not_found_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich the survey candidate recipes\n",
    "\n",
    "Check how many ingredients are in the mapping list, how many are not in that list but are in the ingredients list, and how many are in neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for substitution_tuple, recipe in survey_data:\n",
    "    sub_source, sub_target = substitution_tuple\n",
    "    if \"arcelic_familiar_sub_pair\" not in list(recipe.keys()):\n",
    "        if sub_source in distinct_mapping_targets and sub_target in distinct_mapping_targets:\n",
    "            recipe[\"arcelic_familiar_sub_pair\"] = True\n",
    "        else:\n",
    "            recipe[\"arcelic_familiar_sub_pair\"] = False\n",
    "\n",
    "    for recipe_ingredientrecipe in [\"ingredients\"]:\n",
    "        ingredient_mapped = False\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n",
      "915\n"
     ]
    }
   ],
   "source": [
    "# check the results:\n",
    "# how many samples have sub pairs that are not mappable?\n",
    "samples_with_mapped_sub_pairs = []\n",
    "samples_with_not_mapped_sub_pairs = []\n",
    "for sample in survey_data:\n",
    "    substitution_tuple, recipe = sample\n",
    "    if recipe[\"arcelic_familiar_sub_pair\"]:\n",
    "        samples_with_mapped_sub_pairs.append(sample)\n",
    "    else:\n",
    "        samples_with_not_mapped_sub_pairs.append(sample)\n",
    "\n",
    "print(len(samples_with_mapped_sub_pairs))\n",
    "print(len(samples_with_not_mapped_sub_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "for substitution_tuple, recipe, sample_id in qualtrics_data:\n",
    "    sub_source, sub_target = substitution_tuple\n",
    "    if \"arcelic_familiar_sub_pair\" not in list(recipe.keys()):\n",
    "        if sub_source in distinct_mapping_targets and sub_target in distinct_mapping_targets:\n",
    "            recipe[\"arcelic_familiar_sub_pair\"] = True\n",
    "        else:\n",
    "            recipe[\"arcelic_familiar_sub_pair\"] = False\n",
    "\n",
    "    for recipe_ingredientrecipe in [\"ingredients\"]:\n",
    "        ingredient_mapped = False\n",
    "\n",
    "# check the results:\n",
    "# how many samples have sub pairs that are not mappable?\n",
    "qsamples_with_mapped_sub_pairs = []\n",
    "qsamples_with_not_mapped_sub_pairs = []\n",
    "for sample in qualtrics_data:\n",
    "    substitution_tuple, recipe, sample_id = sample\n",
    "    if recipe[\"arcelic_familiar_sub_pair\"]:\n",
    "        qsamples_with_mapped_sub_pairs.append(sample)\n",
    "    else:\n",
    "        qsamples_with_not_mapped_sub_pairs.append(sample)\n",
    "\n",
    "print(len(qsamples_with_mapped_sub_pairs))\n",
    "print(len(qsamples_with_not_mapped_sub_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "['paprika', 'chili_powder']\n",
      "['ground_beef', 'roast_beef']\n",
      "['walnut', 'slivered_almond']\n",
      "['lemon', 'lime']\n",
      "['green_pepper', 'red_bell_pepper']\n",
      "['raisin', 'blueberry']\n",
      "['diced_tomato', 'crushed_tomato']\n",
      "['apple', 'applesauce']\n",
      "['dry_white_wine', 'water']\n",
      "['lean_ground_beef', 'ground_pork']\n",
      "['lean_ground_beef', 'turkey_meat']\n",
      "['white_wine', 'lemon_juice']\n",
      "['semi_sweet_chocolate_chip', 'walnut']\n",
      "['cooked_chicken', 'turkey']\n",
      "['white_vinegar', 'white_wine_vinegar']\n",
      "['chicken', 'turkey_breast']\n",
      "['slivered_almond', 'walnut']\n",
      "['red_wine', 'water']\n",
      "['red_wine', 'white_wine']\n",
      "['ground_turkey', 'lean_ground_beef']\n",
      "['cherry_tomato', 'plum_tomato']\n",
      "['unsweetened_applesauce', 'banana']\n",
      "['pork_tenderloin', 'pork_loin_roast']\n",
      "['fresh_tomato', 'diced_tomato']\n",
      "['ground_chicken', 'turkey']\n",
      "['flank_steak', 'sirloin_steak']\n",
      "['chicken_piece', 'chicken_breast']\n",
      "['extra_lean_ground_beef', 'ground_turkey']\n",
      "['chicken_wing', 'chicken_leg']\n",
      "['lean_ground_turkey', 'beef']\n",
      "['deli_ham', 'bacon']\n",
      "['walnut_piece', 'almond']\n",
      "['walnut_half', 'almond_half']\n",
      "['marsala_wine', 'white_wine']\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "candidate_mapped_sub_pairs = [sp for sp, r in samples_with_mapped_sub_pairs]\n",
    "already_selected_mapped_sub_pairs = [sp for sp, r, i in qsamples_with_mapped_sub_pairs]\n",
    "\n",
    "unique_already_selected_mapped_sub_pairs = []\n",
    "for sub_pair in already_selected_mapped_sub_pairs:\n",
    "    if sub_pair not in unique_already_selected_mapped_sub_pairs:\n",
    "        unique_already_selected_mapped_sub_pairs.append(sub_pair)\n",
    "\n",
    "# print(candidate_mapped_sub_pairs)\n",
    "# print(already_selected_mapped_sub_pairs)\n",
    "potential_additional_sub_pairs = []\n",
    "for sub_pair in candidate_mapped_sub_pairs:\n",
    "    if sub_pair in potential_additional_sub_pairs:\n",
    "        continue\n",
    "    if sub_pair not in already_selected_mapped_sub_pairs:\n",
    "        potential_additional_sub_pairs.append(sub_pair)\n",
    "\n",
    "print(len(potential_additional_sub_pairs))\n",
    "\n",
    "for sub_pair in potential_additional_sub_pairs:\n",
    "    print(sub_pair)\n",
    "\n",
    "print(len(unique_already_selected_mapped_sub_pairs))\n",
    "\n",
    "# for sub_pair in unique_already_selected_mapped_sub_pairs:\n",
    "#     print(sub_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sub_tuples = [\n",
    "    ['ground_beef', 'roast_beef'],\n",
    "    ['dry_white_wine', 'water'],\n",
    "    ['lean_ground_beef', 'ground_pork'],\n",
    "    ['lean_ground_beef', 'turkey_meat'],\n",
    "    ['white_wine', 'lemon_juice'],\n",
    "    ['semi_sweet_chocolate_chip', 'walnut'],\n",
    "    ['chicken', 'turkey_breast'],\n",
    "    ['slivered_almond', 'walnut'],\n",
    "    ['ground_turkey', 'lean_ground_beef'],\n",
    "    ['unsweetened_applesauce', 'banana'],\n",
    "    ['ground_chicken', 'turkey'],\n",
    "    ['flank_steak', 'sirloin_steak'],\n",
    "    ['extra_lean_ground_beef', 'ground_turkey'],\n",
    "    ['lean_ground_turkey', 'beef'],\n",
    "    ['deli_ham', 'bacon'],\n",
    "]\n",
    "len(new_sub_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "new_survey_sub_pairs = [*unique_already_selected_mapped_sub_pairs, *new_sub_tuples]\n",
    "print(len(new_survey_sub_pairs))\n",
    "# for p in new_survey_sub_pairs:\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select samples where sub pair is suggested\n",
    "\n",
    "- sub pair must be included in the sample as suggested for this recipe\n",
    "- numbers with the least number of occurrences of ingredients that canont be matched are included first, then in order\n",
    "- we aim for 7 recipes where the sub tuple was recommended, and fill up to 10 from other recipes\n",
    "- if there are fewer than 7 recipes to choose from, use all of them and padd with more from the other recipes\n",
    "- (Bonus: consider the argelic recipes first for padding up the rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SAMPLES_PER_ORIGINAL_RECOMMENDATION_PATH = os.path.abspath(\"./outputs/survey_candidate_samples.pkl\")\n",
    "with open(ALL_SAMPLES_PER_ORIGINAL_RECOMMENDATION_PATH, \"rb\") as samples_per_original_recommendation_file:\n",
    "            all_samples_per_original_recommendation = pickle.load(samples_per_original_recommendation_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "recipes_per_selected_sub_pair = {(sub_pair[0], sub_pair[1]): all_samples_per_original_recommendation[(sub_pair[0], sub_pair[1])] for sub_pair in new_survey_sub_pairs}\n",
    "print(len(recipes_per_selected_sub_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortRecipesByNrLeastUnmatchedIngredients(recipe_list):\n",
    "    for recipe in recipe_list:\n",
    "        nr_unmatched_ingredients = 0\n",
    "        for ingredient in recipe[\"ingredients\"]:\n",
    "            ingredient_is_unmatched = True\n",
    "            if isinstance(ingredient, list):\n",
    "                for ingredient_variant in ingredient:\n",
    "                    if ingredient_variant in distinct_mapping_targets:\n",
    "                        ingredient_is_unmatched = False\n",
    "            else:\n",
    "                if ingredient in distinct_mapping_targets:\n",
    "                    ingredient_is_unmatched = False\n",
    "            if ingredient_is_unmatched:\n",
    "                nr_unmatched_ingredients += 1\n",
    "        recipe[\"nr_arcelic_unmatched_ingredients\"] = nr_unmatched_ingredients\n",
    "\n",
    "    recipe_list_sorted = sorted(recipe_list, key=lambda x: x[\"nr_arcelic_unmatched_ingredients\"])\n",
    "    return recipe_list_sorted\n",
    "\n",
    "def sample_n_most_familiar_recipes(sorted_recipe_list, n):\n",
    "    unmapped_arcelic_ingredients_count_target = sorted_recipe_list[n][\"nr_arcelic_unmatched_ingredients\"]\n",
    "    viable_recipes = [\n",
    "        recipe for recipe in sorted_recipe_list if recipe[\"nr_arcelic_unmatched_ingredients\"] <= unmapped_arcelic_ingredients_count_target\n",
    "        ]\n",
    "\n",
    "    selected_recipes = random.sample(viable_recipes, n)\n",
    "    return selected_recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "n = 7\n",
    "\n",
    "final_recipes_per_ingredient = {}\n",
    "for sub_tuple, recipes in list(recipes_per_selected_sub_pair.items()):\n",
    "    if len(recipes) <= n:\n",
    "        final_recipes_per_ingredient[sub_tuple] = recipes\n",
    "    else:\n",
    "        final_recipes_per_ingredient[sub_tuple] = sample_n_most_familiar_recipes(sortRecipesByNrLeastUnmatchedIngredients(recipes), n)\n",
    "\n",
    "print(len(final_recipes_per_ingredient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jetze musste ohno die alten rezepte durchwurschtln unde liste offÃ¼lln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecipesSubsAreIngredientsButNotGT(sub_pair, recipes_extended_dict):\n",
    "    gt_source = sub_pair[0]\n",
    "    gt_target = sub_pair[1]\n",
    "\n",
    "    matched_recipes = []\n",
    "    for recipe_id, recipe in list(recipes_extended_dict.items()):\n",
    "        ingredients = recipe[\"ingredients\"]\n",
    "        has_gt_sub_recommendation = False\n",
    "        subs_collection = recipe[\"subs_collection\"]\n",
    "\n",
    "        for sub in subs_collection:\n",
    "            if isinstance(sub[0], list):\n",
    "                sub_source = sub[0][0]\n",
    "                sub_target = sub[0][1]\n",
    "            else:\n",
    "                sub_source = sub[0]\n",
    "                sub_target = sub[1]\n",
    "            if gt_source == sub_source and gt_target == sub_target:\n",
    "                has_gt_sub_recommendation = True\n",
    "                break\n",
    "\n",
    "        if has_gt_sub_recommendation:\n",
    "            continue\n",
    "\n",
    "        for ingredient in ingredients:\n",
    "            for ingredient_variant in ingredient:\n",
    "                if ingredient_variant == gt_source:\n",
    "                    matched_recipes.append(recipe)\n",
    "                else:\n",
    "                    continue\n",
    "    return matched_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "if N < n:\n",
    "    raise RuntimeError(\"total number of requested recipes greater than number of gt recommended recipes\")\n",
    "\n",
    "for sub_pair, recipe_list in list(final_recipes_per_ingredient.items()):\n",
    "    k = N - len(recipe_list) # fill with k recipes to have N recipes per sub tuple total\n",
    "\n",
    "    alternative_recipe_options = getRecipesSubsAreIngredientsButNotGT(sub_pair, recipes_extended_dict)\n",
    "    alternative_recipe_options_sorted = sortRecipesByNrLeastUnmatchedIngredients(alternative_recipe_options)\n",
    "    additinoal_recipes = sample_n_most_familiar_recipes(alternative_recipe_options_sorted, k)\n",
    "    final_recipes_per_ingredient[sub_pair] = [*recipe_list, *additinoal_recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_tuple, recipe_list in list(final_recipes_per_ingredient.items()):\n",
    "    if len(recipe_list) != 10:\n",
    "        print(sub_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the finaly samples into ye trusty olde json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "final_samples = []\n",
    "id_counter = 0\n",
    "for sub_tuple, recipe_list in list(final_recipes_per_ingredient.items()):\n",
    "    for recipe in recipe_list:\n",
    "        final_samples.append([\n",
    "            [sub_tuple[0], sub_tuple[1]],\n",
    "            recipe,\n",
    "            id_counter\n",
    "            ])\n",
    "        id_counter += 1\n",
    "\n",
    "random.shuffle(final_samples)\n",
    "\n",
    "print(len(final_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finally print the stuff to the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SURVEY_QUESTION_500_SET_PATH, \"w\") as restrianed_samples_file:\n",
    "    json.dump(final_samples, restrianed_samples_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the survey samples more diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath(\"./outputs/recipes_to_substitution_tuple_candidate_common_filtered.pkl\"), \"rb\") as tmp_res_file:\n",
    "    recipes_to_substitution_tuple_candidates = pickle.load(tmp_res_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_for_subs_from_rec_per_sub(recipes_per_sub_tuple: list, source :str, target: str = None) -> list:\n",
    "    results = {}\n",
    "\n",
    "    for sub_tuple, recipe_list in recipes_per_sub_tuple:\n",
    "        if source in sub_tuple[0] and (target is None or (target is not None and target in sub_tuple[1])):\n",
    "            results[sub_tuple] = recipe_list\n",
    "\n",
    "    results = dict(sorted(results.items(), key=lambda item: len(item[1]), reverse = True))\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict: list, source :str, target: str = None) -> list:\n",
    "    results = {}\n",
    "    for recipe_id, recipe in list(recipes_extended_dict.items()):\n",
    "        subs_collection = recipe[\"subs_collection\"]\n",
    "        for sub in subs_collection:\n",
    "            if isinstance(sub[0], list):\n",
    "                sub_source = sub[0][0]\n",
    "                sub_target = sub[0][1]\n",
    "            else:\n",
    "                sub_source = sub[0]\n",
    "                sub_target = sub[1]\n",
    "            if source == sub_source and (target is None or (target is not None and target == sub_target)):\n",
    "                if (sub_source, sub_target) not in results:\n",
    "                    results[(sub_source, sub_target)] = []\n",
    "                results[(sub_source, sub_target)].append(recipe)\n",
    "    results = dict(sorted(results.items(), key=lambda item: len(item[1]), reverse = True))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate some interesting ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cheese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples981\n"
     ]
    }
   ],
   "source": [
    "source = \"cheese\"\n",
    "# target = \"tofu\"\n",
    "target = None\n",
    "\n",
    "#cheese_all_samples[('cottage_cheese', 'egg')]\n",
    "#cheese_all_samples[('ricotta_cheese', 'fresh_spinach')]\n",
    "#cheese_all_samples[('cream_cheese', 'greek_yogurt')]\n",
    "\n",
    "\n",
    "cheese_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "cheese_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(cheese_recommended_samples)} \\n found all source tuples{len(cheese_all_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples483\n"
     ]
    }
   ],
   "source": [
    "source = \"egg\"\n",
    "# target = \"pea\"\n",
    "target = None\n",
    "\n",
    "##egg_all_samples[('egg', 'applesauce')]\n",
    "#egg_all_samples[('egg', 'banana')]\n",
    "#egg_all_samples[('egg', 'tofu')]\n",
    "##egg_all_samples[('egg', 'soymilk')]\n",
    "\n",
    "egg_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "egg_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(egg_recommended_samples)} \\n found all source tuples{len(egg_all_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples206\n"
     ]
    }
   ],
   "source": [
    "source = \"sour_cream\"\n",
    "# target =\"yoghurt\"\n",
    "target = None\n",
    "\n",
    "# cream_all_samples[('sour_cream', 'yoghurt')]\n",
    "# cream_all_samples[('sour_cream', 'ricotta_cheese')]\n",
    "# cream_all_samples[('sour_cream', 'chive')]\n",
    "\n",
    "cream_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "cream_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(cream_recommended_samples)} \\n found all source tuples{len(cream_all_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples475\n"
     ]
    }
   ],
   "source": [
    "source = \"apple\"\n",
    "# target = \"peach\"\n",
    "target = None\n",
    "\n",
    "# apple_all_samples[('apple', 'peach')]\n",
    "## apple_all_samples[('apple', 'pear')]\n",
    "## apple_all_samples[('applesauce', 'oil')]\n",
    "\n",
    "apple_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "apple_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(apple_recommended_samples)} \\n found all source tuples{len(apple_all_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulgur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples8\n"
     ]
    }
   ],
   "source": [
    "source = \"bulgur\"\n",
    "# target = \"rice\"\n",
    "target = None\n",
    "\n",
    "# bulgur_all_samples[('bulgur_wheat', 'brown_rice')]  # abit low wrt number of recipes\n",
    "# bulgur_all_samples[('bulgur', 'quinoa')]\n",
    "\n",
    "bulgur_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "bulgur_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(bulgur_recommended_samples)} \\n found all source tuples{len(bulgur_all_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meat to Non-Meat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples166\n"
     ]
    }
   ],
   "source": [
    "source = \"turkey\"\n",
    "# target = \"lean_ground_beef\"\n",
    "target = None\n",
    "\n",
    "# turkey_all_samples[('ground_turkey', 'mushroom')]\n",
    "\n",
    "turkey_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "turkey_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(turkey_recommended_samples)} \\n found all source tuples{len(turkey_all_samples)}\")\n",
    "\n",
    "#    [\n",
    "    #   \"ground_turkey\",\n",
    "    #   \"lean_ground_beef\"\n",
    "    # ],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples14\n"
     ]
    }
   ],
   "source": [
    "source = \"beef\"\n",
    "target = \"bean\"\n",
    "# target = None\n",
    "\n",
    "# turkey_all_samples[('ground_beef', 'black_bean')]\n",
    "\n",
    "turkey_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "turkey_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(turkey_recommended_samples)} \\n found all source tuples{len(turkey_all_samples)}\")\n",
    "\n",
    "#    [\n",
    "    #   \"ground_turkey\",\n",
    "    #   \"lean_ground_beef\"\n",
    "    # ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the already prepared survey samples and remove a chunk of potential redundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found recommended source tuples: 0 \n",
      " found all source tuples15\n"
     ]
    }
   ],
   "source": [
    "source = \"cod\"\n",
    "# target = \"bean\"\n",
    "target = None\n",
    "\n",
    "# test_all_samples[('green_bean', 'celery')]\n",
    "# test_all_samples[('tofu', 'ricotta_cheese')]\n",
    "\n",
    "test_recommended_samples = get_samples_for_subs_from_rec_per_sub(recipes_to_substitution_tuple_candidates, source, target)\n",
    "test_all_samples = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, source, target)\n",
    "print(f\"found recommended source tuples: {len(test_recommended_samples)} \\n found all source tuples{len(test_all_samples)}\")\n",
    "\n",
    "#    [\n",
    "    #   \"ground_turkey\",\n",
    "    #   \"lean_ground_beef\"\n",
    "    # ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "35\n",
      "350\n",
      "['arugula', 'spinach']\n",
      "['boneless_skinless_chicken_breast', 'pork']\n",
      "['boneless_skinless_chicken_breast', 'shrimp']\n",
      "['chicken', 'turkey']\n",
      "['cilantro', 'parsley']\n",
      "['date', 'raisin']\n",
      "['dry_white_wine', 'water']\n",
      "['extra_large_shrimp', 'chicken']\n",
      "['flank_steak', 'sirloin_steak']\n",
      "['fresh_basil', 'cilantro']\n",
      "['fresh_cilantro', 'fresh_parsley']\n",
      "['ground_beef', 'lean_ground_turkey']\n",
      "['ground_beef', 'ground_chicken']\n",
      "['ground_beef', 'roast_beef']\n",
      "['ground_lamb', 'ground_beef']\n",
      "['lean_ground_beef', 'ground_pork']\n",
      "['lean_ground_turkey', 'beef']\n",
      "['parsley', 'basil']\n",
      "['pine_nut', 'sunflower_seed']\n",
      "['pork_tenderloin', 'chicken_breast']\n",
      "['pork_tenderloin', 'shrimp']\n",
      "['raisin', 'chocolate']\n",
      "['raisin', 'date']\n",
      "['raisin', 'white_chocolate_chip']\n",
      "['red_wine_vinegar', 'balsamic_vinegar']\n",
      "['red_wine_vinegar', 'lemon_juice']\n",
      "['semi_sweet_chocolate_chip', 'walnut']\n",
      "['slivered_almond', 'walnut']\n",
      "['strawberry', 'blueberry']\n",
      "['turkey', 'chicken']\n",
      "['unsweetened_applesauce', 'banana']\n",
      "['unsweetened_cocoa_powder', 'chocolate']\n",
      "['white_wine', 'white_wine_vinegar']\n",
      "['zucchini', 'yellow_squash']\n",
      "['zucchini', 'banana']\n"
     ]
    }
   ],
   "source": [
    "with open(SURVEY_QUESTION_500_SET_PATH, \"r\") as survey_samples_file:\n",
    "    survey_samples = json.load(survey_samples_file)\n",
    "\n",
    "print(len(survey_samples))\n",
    "\n",
    "filter_out_sub_tuples = [\n",
    "    [\"ground_pork\", \"ground_beef\"],\n",
    "    [\"chicken\", \"turkey_breast\"],\n",
    "    [\"ground_chicken\", \"turkey\"],\n",
    "    [\"cooked_chicken\", \"pork\"],\n",
    "    [\"deli_ham\", \"bacon\"],\n",
    "    [\"ground_pork\", \"ground_beef\"],\n",
    "    [\"ground_turkey\", \"ground_pork\"],\n",
    "    [\"ground_turkey\", \"lean_ground_beef\"],\n",
    "    [\"lean_ground_beef\", \"chicken\"],\n",
    "    [\"lean_ground_beef\", \"turkey\"],\n",
    "    [\"lean_ground_beef\", \"turkey_meat\"],\n",
    "    [\"pork_roast\", \"pork_chop\"],\n",
    "    ['extra_lean_ground_beef', 'ground_turkey'],\n",
    "    ['lean_ground_beef', 'chicken_breast'],\n",
    "    ['white_wine', 'lemon_juice'],\n",
    "    ['ground_pork', 'ground_chicken']\n",
    "]\n",
    "\n",
    "filtered_survey_samples = []\n",
    "filtered_out_tuples = []\n",
    "still_in_tuples = []\n",
    "\n",
    "for sub_tuple, recipe, id in survey_samples:\n",
    "    if sub_tuple in filter_out_sub_tuples:\n",
    "        if sub_tuple not in filtered_out_tuples:\n",
    "            filtered_out_tuples.append(sub_tuple)\n",
    "    else:\n",
    "        filtered_survey_samples.append([sub_tuple, recipe])\n",
    "        if sub_tuple not in still_in_tuples:\n",
    "            still_in_tuples.append(sub_tuple)\n",
    "\n",
    "print(len(still_in_tuples))\n",
    "print(len(filtered_survey_samples))\n",
    "for pair in list(sorted(still_in_tuples, key=lambda x: x[0])):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load new recipes for the new interesting sub pairs for more diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "new_recipes_per_sub_pair = {\n",
    "    ('cottage_cheese', 'egg'): [],\n",
    "    ('ricotta_cheese', 'fresh_spinach'): [],\n",
    "    ('cream_cheese', 'greek_yogurt'): [],\n",
    "    ('egg', 'banana'): [],\n",
    "    ('egg', 'tofu'): [],\n",
    "    ('sour_cream', 'yoghurt'): [],\n",
    "    ('sour_cream', 'ricotta_cheese'): [],\n",
    "    ('sour_cream', 'chive'): [],\n",
    "    ('apple', 'peach'): [],\n",
    "    ('bulgur_wheat', 'brown_rice'): [],\n",
    "    ('bulgur', 'quinoa'): [],\n",
    "    ('ground_turkey', 'mushroom'): [],\n",
    "    ('ground_beef', 'black_bean'): [],\n",
    "    ('green_bean', 'celery'): [],\n",
    "    ('tofu', 'ricotta_cheese'): []\n",
    "}\n",
    "\n",
    "n = 7\n",
    "for sub_pair, _r in list(new_recipes_per_sub_pair.items()):\n",
    "    recipes = get_samples_for_subs_from_rec_ext_dic(recipes_extended_dict, sub_pair[0], sub_pair[1])[sub_pair]\n",
    "\n",
    "    if len(recipes) <= n:\n",
    "        new_recipes_per_sub_pair[(sub_pair[0], sub_pair[1])] = recipes\n",
    "    else:\n",
    "        new_recipes_per_sub_pair[(sub_pair[0], sub_pair[1])] = sample_n_most_familiar_recipes(sortRecipesByNrLeastUnmatchedIngredients(recipes), n)\n",
    "\n",
    "print(len(new_recipes_per_sub_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "if N < n:\n",
    "    raise RuntimeError(\"total number of requested recipes greater than number of gt recommended recipes\")\n",
    "\n",
    "for sub_pair, recipe_list in list(new_recipes_per_sub_pair.items()):\n",
    "    k = N - len(recipe_list) # fill with k recipes to have N recipes per sub tuple total\n",
    "\n",
    "    alternative_recipe_options = getRecipesSubsAreIngredientsButNotGT(sub_pair, recipes_extended_dict)\n",
    "    alternative_recipe_options_sorted = sortRecipesByNrLeastUnmatchedIngredients(alternative_recipe_options)\n",
    "    additinoal_recipes = sample_n_most_familiar_recipes(alternative_recipe_options_sorted, k)\n",
    "    new_recipes_per_sub_pair[sub_pair] = [*recipe_list, *additinoal_recipes]\n",
    "\n",
    "for sub_tuple, recipe_list in list(new_recipes_per_sub_pair.items()):\n",
    "    if len(recipe_list) != 10:\n",
    "        print(sub_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now combine the old and the new and create the sample set :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_survey_samples))\n",
    "\n",
    "for sub_tuple, recipe_list in list(new_recipes_per_sub_pair.items()):\n",
    "    for recipe in recipe_list:\n",
    "        filtered_survey_samples.append([[sub_tuple[0], sub_tuple[1]], recipe])\n",
    "\n",
    "print(len(filtered_survey_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['white_wine', 'white_wine_vinegar'], {'id': 'b4846b1f6b', 'ingredients': [['ham', 'reduced_sodium_ham'], ['butter', 'molly_mcbutter'], ['bay_leaf', 'bay_leaves'], ['garlic_clove', 'garlic_cloves'], ['dried_thyme'], ['parsley'], ['onion', 'onions', 'round_onion'], ['white_wine', 'rhine_wine'], ['sweet_paprika'], ['salt', 'vegetable_salt', 'low_sodium_salt'], ['lemon', 'lemons']], 'subs': ['ham', 'roast'], 'instructions': ['Preheat oven to 350 degrees F.', 'Score the skin and fat of the fresh ham.', 'Place in a shallow roasting pan (in Spain they use an oval earthenware one) and rub the skin with the butter.', 'Combine bay leaves, garlic, thyme, parsley and minced onion; sprinkle this over the meat.', 'Next sprinkle meat with the juice of 1 lemon, 1/3 cup white wine, sweet paprika and salt.', 'Roast meat for 1-1/2 hours.', 'Remove fat that has accumulated in the pan.', 'Add to pan: 1/3 cup white wine and 1 cup water.', 'Continue to roast for 3-1/2 to 4-1/2 hours longer, or a total of 25 minutes per pound, basting every half hour with the pan juices.'], 'title': \"Vincent Price's Roast Pork Castilian Style\", 'original_ingredients': ['1 (12 lb) fresh ham', '4 tablespoons butter', '3 bay leaves, crumbled', '3 cloves garlic, minced', '12 teaspoon dried thyme', '2 tablespoons chopped parsley', '3 tablespoons minced onions', '23 cup white wine, divided', '2 tablespoons sweet paprika', '2 teaspoons salt', '1 lemon, juice of'], 'ingredient_quantities': {'1 (12 lb) fresh ham': 1.0, '4 tablespoons butter': 59.1472, '3 bay leaves, crumbled': 3.0, '3 cloves garlic, minced': 15.0, '12 teaspoon dried thyme': 2.46446, '2 tablespoons chopped parsley': 29.5736, '3 tablespoons minced onions': 44.3604, '23 cup white wine, divided': 157.7253333333333, '2 tablespoons sweet paprika': 29.5736, '2 teaspoons salt': 9.85784, '1 lemon, juice of': 1.0}, 'subs_collection': [['ham', 'roast'], ['white_wine', 'white_wine_vinegar']]}, 0]\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(filtered_survey_samples)\n",
    "for i, sample in enumerate(filtered_survey_samples):\n",
    "    sample.append(i)\n",
    "\n",
    "print(filtered_survey_samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the updated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SURVEY_QUESTION_500_UPDATED_SET_PATH, \"w\") as enriched:\n",
    "    json.dump(filtered_survey_samples, enriched, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodrecommnederscrapbooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
